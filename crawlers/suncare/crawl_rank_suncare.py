from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import json
import datetime
from seleniumbase import SB
from bs4 import BeautifulSoup

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ARM64 ì•„í‚¤í…ì²˜ìš© ë“œë¼ì´ë²„ ë‹¤ìš´ë¡œë“œ ë° uc ê´€ë ¨ ê¶Œí•œ ê²½ë¡œ ì§€ì •)
import os
os.environ['WDM_ARCH'] = 'arm64'
os.environ["UC_DRIVER_PATH"] = "/opt/airflow/uc_driver"

def get_top100_suncare() -> tuple:
    chrome_options = Options()
    chrome_options.add_argument('--headless=new') 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

    # ì˜¬ë¦¬ë¸Œì˜ ì„ ì¼€ì–´ ë­í‚¹ í˜ì´ì§€ ì—´ê¸°
    url = "https://www.oliveyoung.co.kr/store/main/getBestList.do?dispCatNo=900000100100001&fltDispCatNo=10000010011&pageIdx=1&rowsPerPage=8"
    driver.get(url)

    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
    time.sleep(2.5)
    
    data = []
    goods_no_list = []
    items = driver.find_elements(
        By.CSS_SELECTOR, "div.TabsConts.on ul.cate_prd_list li"
    )
    print(f"ğŸ“¦ ìƒí’ˆ ìˆ˜ì§‘ ì‹œë„: {len(items)}ê°œ")
    
    rank = 1
    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    collected_at = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    for item in items:
        try:
            # ìˆœìœ„ (.thumb_flag ìš”ì†Œê°€ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„)
            try:
                rank_tag = item.find_element(By.CSS_SELECTOR, ".thumb_flag")
                if rank_tag.text.strip().isdigit():
                    rank_val = int(rank_tag.text.strip())
                    rank = rank_val
                else:
                    rank_val = rank
            except Exception:
                rank_val = rank

            try:
                # ë¸Œëœë“œ
                brand = item.find_element(By.CSS_SELECTOR, ".tx_brand").text.strip()
                # ì œí’ˆëª…
                name = item.find_element(By.CSS_SELECTOR, ".tx_name").text.strip()
                # ì œí’ˆ ì½”ë“œ (goodsNo)
                try:
                    a_tag = item.find_element(By.CSS_SELECTOR, "a[data-ref-goodsno]")
                    goods_no = a_tag.get_attribute("data-ref-goodsno")
                except Exception:
                    goods_no = ""
                # goods_no_listì— ë°”ë¡œ ì¶”ê°€
                if goods_no:
                    goods_no_list.append(goods_no)
                # ì •ê°€ (null í—ˆìš©)
                try:
                    price_original = item.find_element(
                        By.CSS_SELECTOR, ".prd_price .tx_org .tx_num"
                    ).text.strip()
                except Exception:
                    price_original = ""
                # êµ¬ë§¤ê°€ê²©
                try:
                    price_final = item.find_element(
                        By.CSS_SELECTOR, ".prd_price .tx_cur .tx_num"
                    ).text.strip()
                except Exception as e:
                    print(f"êµ¬ë§¤ê°€ê²© ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    price_final = ""
                # ê¸°íƒ€ í”„ë¡œëª¨ì…˜ ì •ë³´(null í—ˆìš©)
                try:
                    flag_spans = item.find_elements(By.CSS_SELECTOR, ".prd_flag .icon_flag")
                    flag_list = [
                        span.text.strip() for span in flag_spans if span.text.strip()
                    ]
                except Exception:
                    flag_list = []
            except Exception as e:
                print(f"ì œí’ˆ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue

            # ì˜¬ë¦¬ë¸Œì˜ PB ë¸Œëœë“œ ì—¬ë¶€ í™•ì¸
            pb_brands = [
                "ë°”ì´ì˜¤í ë³´",
                "ë¸Œë§ê·¸ë¦°",
                "ì›¨ì´í¬ë©”ì´í¬",
                "ì»¬ëŸ¬ê·¸ë¨",
                "í•„ë¦¬ë°€ë¦¬",
                "ì•„ì´ë””ì–¼í¬ë§¨",
                "ë¼ìš´ë“œì–´ë¼ìš´ë“œ",
                "ì‹ë¬¼ë‚˜ë¼",
                "ì¼€ì–´í”ŒëŸ¬ìŠ¤",
                "íƒ„íƒ„",
                "ë”œë¼ì´íŠ¸ í”„ë¡œì íŠ¸",
            ]
            is_pb = 1 if brand in pb_brands else 0

            # ì¼ì‹œí’ˆì ˆ ì—¬ë¶€ í™•ì¸
            try:
                soldout_flag = item.find_element(By.CSS_SELECTOR, "span.status_flag.soldout")
                is_soldout = soldout_flag.is_displayed()
            except Exception:
                is_soldout = False

            data.append(
                {
                    "rank": rank_val,
                    "brandName": brand,
                    "isPb": is_pb,
                    "goodsName": name,
                    "salePrice": price_final,
                    "originalPrice": price_original,
                    "flagList": flag_list,  # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
                    "createdAt": collected_at,
                    "isSoldout": bool(is_soldout)
                }
            )
            rank += 1

        except Exception as e:
            print(f"ì œí’ˆ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue

    driver.quit()

    return data, goods_no_list


def get_product_detail_info(sb, goods_no: str) -> dict:
    url = f"https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo={goods_no}"
    sb.uc_open_with_reconnect(url, reconnect_time=5)
    time.sleep(1)
    html = sb.driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    
    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    try:
        category = soup.select_one("a.cate_y#midCatNm").text.strip()
    except Exception as e:
        print(f"ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        category = ""

    # ëŒ€í‘œ ì½”ë©˜íŠ¸
    try:
        comment_tag = soup.select_one("p.img_face em")
        total_comment = comment_tag.text.strip() if comment_tag else ""
    except Exception as e:
        print(f"ëŒ€í‘œ ì½”ë©˜íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
        total_comment = ""
    
    # ì´ë¦¬ë·°ìˆ˜
    try:
        review_info = soup.select_one("#repReview em")
        total_review = int(review_info.text.strip().replace("(", "").replace("ê±´)", "").replace(",", ""))
    except Exception as e:
        print(f"ì´ ë¦¬ë·°ìˆ˜ íŒŒì‹± ì‹¤íŒ¨: {e}")
        total_review = 0

    # ë¦¬ë·°í‰ì 
    try:
        review_score = soup.select_one("#repReview b")
        review_score = float(review_score.text.strip())
    except Exception as e:
        print(f"ë¦¬ë·°í‰ì  íŒŒì‹± ì‹¤íŒ¨: {e}")
        review_score = None

    # ë¦¬ë·° ë¶„í¬ ê¸°ë³¸ê°’
    pctOf5 = pctOf4 = pctOf3 = pctOf2 = pctOf1 = None
    review_detail = ""

    # ë¦¬ë·°ê°€ 1ê±´ ì´ìƒ ìˆì„ ë•Œë§Œ ë¦¬ë·°íƒ­ í´ë¦­ ë° ë¶„í¬ ìˆ˜ì§‘
    if total_review > 0:
        try:
            sb.click("a.goods_reputation")
            WebDriverWait(sb.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "ul.graph_list span.per"))
            )
            percent_elements = sb.find_elements("css selector", "ul.graph_list span.per")
            percent_list = [el.text.strip() for el in percent_elements]
            if len(percent_list) == 5:
                pctOf5 = percent_list[0]
                pctOf4 = percent_list[1]
                pctOf3 = percent_list[2]
                pctOf2 = percent_list[3]
                pctOf1 = percent_list[4]

            # reviewDetail ì •ë³´
            review_detail = []
            polls = sb.find_elements("css selector", "dl.poll_type2.type3")
            for poll in polls:
                try:
                    title = poll.find_element("css selector", "span").text.strip()
                    li_tags = poll.find_elements("css selector", "ul.list > li")
                    for li in li_tags:
                        label = li.find_element("css selector", "span.txt").text.strip()
                        percent = li.find_element("css selector", "em.per").text.strip()
                        review_detail.append({
                            "type": title,
                            "value": label,
                            "gauge": percent
                        })
                except Exception as e:
                    print(f"ë¦¬ë·° ì„¤ë¬¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            review_detail = json.dumps(review_detail, ensure_ascii=False)

        except Exception as e:
            print("ë¦¬ë·° ì •ë³´ ì—†ìŒ:", e)

    # === ìƒì„¸ìŠ¤í™(êµ¬ë§¤ì •ë³´) ì¶”ì¶œ ===
    # êµ¬ë§¤ì •ë³´ íƒ­ í´ë¦­
    try:
        sb.click("a.goods_buyinfo")
        time.sleep(3)  # ajax ë¡œë”© ëŒ€ê¸°
        html = sb.driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
    except Exception as e:
        print("êµ¬ë§¤ì •ë³´ íƒ­ í´ë¦­ ì‹¤íŒ¨:", e)

    # === í•œê¸€ í‚¤ â†’ ì˜ì–´ í‚¤ ë§¤í•‘ ===
    title_map = {
        "ìš©ëŸ‰": "capacity",
        "ì£¼ìš” ì‚¬ì–‘": "detail",
        "ëª¨ë“  ì„±ë¶„": "ingredient"
    }

    # ê¸°ë³¸ê°’ ì„¸íŒ…
    detail_spec = {
        "capacity": "",
        "detail": "",
        "ingredient": ""
    }

    try:
        dl_tags = soup.select("div#artcInfo dl.detail_info_list")
        for dl in dl_tags:
            dt = dl.select_one("dt")
            dd = dl.select_one("dd")
            if dt and dd:
                dt_text = dt.text.strip()
                dd_text = dd.text.strip()

                for kr_title, en_key in title_map.items():
                    if kr_title in dt_text:
                        detail_spec[en_key] = dd_text
    except Exception as e:
        print(f"[ìƒì„¸ ìŠ¤í™ íŒŒì‹± ì˜¤ë¥˜]: {e}")

    return {
        "category": category,
        "totalComment": total_comment,
        "numOfReviews": total_review,
        "avgReview": review_score,
        "pctOf5": pctOf5,
        "pctOf4": pctOf4,
        "pctOf3": pctOf3,
        "pctOf2": pctOf2,
        "pctOf1": pctOf1,
        "reviewDetail": review_detail,
        **detail_spec,
    }

##### ì‹¤í–‰ ì½”ë“œ #####
# data, goods_no_list = get_top100_suncare()
# with SB(uc=True, test=True) as sb:
#     detail_list = []
#     for goods_no in goods_no_list:
#         detail = get_product_detail_info(sb, goods_no)
#         detail_list.append(detail)
# df = pd.DataFrame(data)
# detail_df = pd.DataFrame(detail_list)
# result_df = pd.concat([df.reset_index(drop=True), detail_df.reset_index(drop=True)], axis=1)
# now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
# filename = f"suncare_result_{now}.json"
# result_df.to_json(filename, orient='records', force_ascii=False, indent=2)
# print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")
# print(f"ì´ {len(result_df)}ê°œ ìƒí’ˆ ì €ì¥ë¨")